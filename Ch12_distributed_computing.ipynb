{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch12_distributed_computing.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"dLnv1SosLpL8","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","%matplotlib inline\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SVBO4FwYJ9N5","colab_type":"text"},"cell_type":"markdown","source":["#Multiple Devices on a Single Machine\n","##Installation\n","Download and install the appropriate version of the CUDA and cuDNN libraries.\n","\n","\n","Nvidia’s *Compute Unified Device Architecture library* (CUDA) allows developers to use CUDA-enabled GPUs for all sorts of computations (not just graphics acceleration). Nvidia’s *CUDA Deep Neural Network* library (cuDNN) is a GPU-accelerated library of primitives for DNNs. It provides optimized implementations of common DNN computations such as activation layers, normalization, forward and backward convolutions, and pooling.\n","\n","Use **nvidia-smi** to check that CUDA is properly installed\n","\n","Install TensorFlow with GPU support, **pip3 install --upgrade tensorflow-gpu**"]},{"metadata":{"id":"ZeJg52Djb2VJ","colab_type":"text"},"cell_type":"markdown","source":["##Managing the GPU RAM\n","By default TensorFlow automatically grabs all the RAM in all available GPUs the first time you run a graph.\n","\n","To run each process on different GPU cards, set the **CUDA_VISIBLE_DEVICES** environment variable"]},{"metadata":{"id":"V9l6RFqdccMH","colab_type":"code","colab":{}},"cell_type":"code","source":["$ CUDA_VISIBLE_DEVICES=0,1 python3 program_1.py\n","# and in another terminal:\n","$ CUDA_VISIBLE_DEVICES=3,2 python3 program_2.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RiFG6IIrcfjS","colab_type":"text"},"cell_type":"markdown","source":["Program #1 will only see GPU cards 0 and 1 (numbered 0 and 1, respectively), and\n","program #2 will only see GPU cards 2 and 3 (numbered 1 and 0, respectively)."]},{"metadata":{"id":"Tz7y0WRcchb-","colab_type":"text"},"cell_type":"markdown","source":["Or, you can tell TensorFlow to grab only a fraction of the memory.\n","\n","For example, to make TensorFlow grab 40% of each GPU's memory"]},{"metadata":{"id":"HIBu6fSPcvSI","colab_type":"code","colab":{}},"cell_type":"code","source":["config = tf.ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.4\n","session = tf.Session(config=config)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4VPZf6uUc7oq","colab_type":"text"},"cell_type":"markdown","source":["Now two programs like this one can run in parallel using the same GPU cards (but\n","not three, since 3 × 0.4 > 1)."]},{"metadata":{"id":"Mkim8NjodKUe","colab_type":"text"},"cell_type":"markdown","source":["##Placing Operations on Devices"]},{"metadata":{"id":"m3f9W80xdZ3i","colab_type":"text"},"cell_type":"markdown","source":["###Simple placement"]}]}